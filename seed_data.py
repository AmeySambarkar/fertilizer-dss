# ... (Full seed_data.py content from previous correct version) ...
import os, random, re, json, traceback; import numpy as np; import pandas as pd; from faker import Faker; from sqlalchemy import create_engine, text; from geoalchemy2 import WKTElement; from dotenv import load_dotenv; from datetime import date, timedelta
load_dotenv(); DATABASE_URL = f"postgresql+psycopg2://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@db:{os.getenv('POSTGRES_PORT')}/{os.getenv('POSTGRES_DB')}"
TARGET_ROWS = 6000; CSV_FILE_PATH = 'dataa/Vegetable_Cultivation_Analysis_Sheet_1_Table_1_Vegetable_Co.csv'; HEADER_ROW = 1
fake = Faker('en_IN'); LAT_RANGE = (18.2, 19.0); LON_RANGE = (73.5, 74.5); AREA_HA_RANGE = (0.5, 5.0); PH_RANGE = (6.0, 8.5); SOIL_N_RANGE = (15, 60); SOIL_P_RANGE = (8, 30); SOIL_K_RANGE = (100, 300); PLANTING_WINDOW_START = date(2022, 1, 1); PLANTING_WINDOW_END = date(2023, 12, 31)
def load_crops_from_csv(filepath, header_row):
    try:
        df = pd.read_csv(filepath, header=header_row); print(f"CSV loaded. Columns: {df.columns.tolist()}"); name_col = 'English Name'; yield_low_col = 'Productivity over 1 life cycle, kg per ha'; yield_high_col = 'Productivity over 1 life cycle, kg per ha.2'; duration_col = 'Life Span, Months'; relevant_cols = {name_col: 'crop_name', yield_low_col: 'yield_low', yield_high_col: 'yield_high', duration_col: 'duration_months'}; missing_cols = [col for col in relevant_cols if col not in df.columns];
        if missing_cols: raise ValueError(f"Missing columns: {missing_cols}. Have: {df.columns.tolist()}"); crop_df = df[list(relevant_cols.keys())].rename(columns=relevant_cols); crop_df = crop_df.dropna(subset=['crop_name']); crop_df = crop_df[crop_df['crop_name'].str.strip() != '']; crop_df['yield_low'] = pd.to_numeric(crop_df['yield_low'], errors='coerce'); crop_df['yield_high'] = pd.to_numeric(crop_df['yield_high'], errors='coerce');
        def parse_duration(d):
            if pd.isna(d): return None; nums = re.findall(r'\d+\.?\d*', str(d));
            if nums: return max(float(n) for n in nums);
            elif 'annual' in str(d).lower(): return 12.0; return None
        crop_df['duration_months_numeric'] = crop_df['duration_months'].apply(parse_duration); crop_df = crop_df.dropna(subset=['yield_low', 'yield_high', 'duration_months_numeric']); crop_df['duration_days'] = (crop_df['duration_months_numeric'] * 30).astype(int); crop_df = crop_df[crop_df['yield_low'] <= crop_df['yield_high']]; crop_df['crop_name'] = crop_df['crop_name'].str.lower().str.strip(); crops_dict = {}
        for _, row in crop_df.iterrows():
            if row['yield_high'] - row['yield_low'] < 10: y_avg = (row['yield_low'] + row['yield_high']) / 2; y_range = (y_avg * 0.95, y_avg * 1.05)
            else: y_range = (row['yield_low'], row['yield_high'])
            crops_dict[row['crop_name']] = {'yield_range': y_range, 'duration': row['duration_days']}
        print(f"Processed {len(crops_dict)} crops.");
        if not crops_dict: raise ValueError("No valid crop data loaded."); return crops_dict
    except FileNotFoundError: print(f"ERROR: CSV not found at {filepath}"); raise
    except Exception as e: print(f"ERROR processing CSV: {e}"); traceback.print_exc(); raise
try: CROPS = load_crops_from_csv(CSV_FILE_PATH, HEADER_ROW)
except Exception: print("Exiting."); exit(1)
def generate_field_data(num_fields): fields = []; for i in range(num_fields): lat = round(random.uniform(*LAT_RANGE), 6); lon = round(random.uniform(*LON_RANGE), 6); area = round(random.uniform(*AREA_HA_RANGE), 2); lon_off = 0.001*random.uniform(0.8, 1.2); lat_off = 0.001*random.uniform(0.8, 1.2); wkt = f'POLYGON(({lon - lon_off} {lat - lat_off}, {lon + lon_off} {lat - lat_off}, {lon + lon_off} {lat + lat_off}, {lon - lon_off} {lat + lat_off}, {lon - lon_off} {lat - lat_off}))'; fields.append({'id': f'field_{i+1}', 'farm_id': None, 'field_name': f'Field {i+1} ({fake.word().capitalize()})', 'geom': WKTElement(wkt, srid=4326), 'area_hectares': area, 'lat': lat, 'lon': lon}); return pd.DataFrame(fields)
def generate_growing_season_data(fields_df, target_rows): seasons = []; num_fields = len(fields_df); rows_per_field = max(1, target_rows // num_fields); available_crops = list(CROPS.keys()); if not available_crops: raise ValueError("No crops available."); for _, field in fields_df.iterrows(): for i in range(rows_per_field): crop_name = random.choice(available_crops); crop_info = CROPS[crop_name]; days_off = random.randint(0, (PLANTING_WINDOW_END - PLANTING_WINDOW_START).days); p_date = PLANTING_WINDOW_START + timedelta(days=days_off); duration = crop_info.get("duration", 120); h_date = p_date + timedelta(days=duration + random.randint(-15, 15)); year = p_date.year; y_low, y_high = crop_info.get("yield_range", (1000, 3000)); base_y = random.uniform(y_low, y_high); noise = 1 + random.uniform(-0.1, 0.1) + (field['area_hectares'] - np.mean(AREA_HA_RANGE)) * 0.02; final_y = round(max(0, base_y * noise), 2); soil_n = round(random.uniform(*SOIL_N_RANGE)*(1+random.uniform(-0.1,0.1)), 2); soil_p = round(random.uniform(*SOIL_P_RANGE)*(1+random.uniform(-0.1,0.1)), 2); soil_k = round(random.uniform(*SOIL_K_RANGE)*(1+random.uniform(-0.1,0.1)), 2); ph = round(random.uniform(*PH_RANGE), 1); soil_snap = {"n_kg_ha": soil_n, "p_olsen_mg_kg": soil_p, "k_mg_kg": soil_k, "ph": ph, "organic_carbon_pct": round(random.uniform(0.5, 1.5), 2)}; seasons.append({'field_id': field['id'], 'crop': crop_name, 'season_year': year, 'planting_date': p_date, 'harvest_date': h_date, 'final_yield_kg_per_ha': final_y, 'soil_snapshot': soil_snap}); if len(seasons) >= target_rows: break; if len(seasons) >= target_rows: break; return pd.DataFrame(seasons)
if __name__ == "__main__":
    print(f"Connecting: {DATABASE_URL.replace(os.getenv('POSTGRES_PASSWORD', '****'), '****')}")
    try:
        engine = create_engine(DATABASE_URL);
        with engine.connect() as conn: print("Connected."); confirm = input("Clear existing 'field' & 'growing_season' data? Type 'yes': ");
            if confirm.lower() == 'yes': print("Clearing..."); conn.execute(text("TRUNCATE TABLE growing_season CASCADE;")); conn.execute(text("TRUNCATE TABLE field CASCADE;")); conn.commit(); print("Cleared.")
            else: print("Aborting."); exit()
            num_fields = max(10, TARGET_ROWS // 5); print(f"Generating {num_fields} fields..."); fields_df = generate_field_data(num_fields); print("Inserting fields..."); fields_df.to_sql('field', engine, if_exists='append', index=False, dtype={'geom': 'Geometry'}); print(f"{len(fields_df)} fields done."); print(f"Generating ~{TARGET_ROWS} seasons from CSV..."); seasons_df = generate_growing_season_data(fields_df, TARGET_ROWS); print("Inserting seasons..."); seasons_df['soil_snapshot'] = seasons_df['soil_snapshot'].apply(json.dumps); seasons_df.to_sql('growing_season', engine, if_exists='append', index=False, dtype={'soil_snapshot': 'JSONB'}); print(f"{len(seasons_df)} seasons done."); print("Seeding complete.")
    except Exception as e: print(f"\nError: {e}"); print("Checks:"); print(f"1. CSV at '{CSV_FILE_PATH}'?"); print(f"2. CSV columns match script (Header row {HEADER_ROW+1})?"); print("3. DB running?"); print("4. .env correct?"); print("5. schema.sql ran?"); traceback.print_exc()
